{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "mount_file_id": "1fPoF-BnFcgFcRH_F9_kDrp7pQOEUhBNv",
      "authorship_tag": "ABX9TyNGqvoBLzDswoY0RUug1Y3u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zentralwerkstatt/fau/blob/main/fau.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN77qowyZMwz"
      },
      "source": [
        "# Image Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This notebook requires a GPU - make sure to change the runtime type in the \"runtime\" menu!**"
      ],
      "metadata": {
        "id": "tdc9CoRHHzH9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv64COI6N5Rv"
      },
      "source": [
        "## Copyright notice\n",
        "\n",
        "This version (c) 2024 Fabian Offert, [MIT License](LICENSE)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Access utility functions"
      ],
      "metadata": {
        "id": "g4R1QZfT_xCc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFs6gNiNN5Ry"
      },
      "source": [
        "%%capture\n",
        "!rm -rf toolbox\n",
        "!git clone https://github.com/zentralwerkstatt/toolbox\n",
        "!pip3 install git+https://github.com/openai/CLIP.git\n",
        "!pip3 install umap-learn filetype\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\",category=FutureWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "zq1Hgkt7_7hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import PIL.Image\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.cluster import KMeans\n",
        "from toolbox import toolbox\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "PxtHkgqX_vOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting some test data \"locally\" (Web gallery of art)\n"
      ],
      "metadata": {
        "id": "T7YjPtNk_jHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!rm -rf wga\n",
        "!gdown --id 10eyHTKDDqN7iwu0WDCaq2sZtOCQ3w9Fs\n",
        "!unzip wga.zip -d .\n",
        "!rm wga.zip"
      ],
      "metadata": {
        "id": "JpCRxBgY_i2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPZWjIbztNGn"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-ZLeOpWZ_90"
      },
      "source": [
        "## 1. Individual images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfcFcmXIHcn8"
      },
      "source": [
        "### Opening and displaying images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MP6ZASibVGE"
      },
      "source": [
        "# Let's get a test image\n",
        "img = toolbox.img_from_url(\"https://c.files.bbci.co.uk/8D30/production/_106344163_florida_python_.big_cypressjpg.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzqdjCB1bmH1"
      },
      "source": [
        "img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Within a loop, use:\n",
        "toolbox.show_img(img)"
      ],
      "metadata": {
        "id": "gNVIDPpIyf14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVr2naH0tVw6"
      },
      "source": [
        "### Resizing images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_TgCJUsbu7-"
      },
      "source": [
        "This image is too big, but we can easily resize it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ9BapaibzLl"
      },
      "source": [
        "img_small = img.resize((img.width//2, img.height//3)) # Floor division\n",
        "img_small"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX3bDYQCB7Fd"
      },
      "source": [
        "If we are not sure how big our original image is, we can use the `thumbnail` function to resize the image to a min/max size while keeping the aspect ratio. Caution: this functions changes an image in-place, i.e. the function does not return a new variable but changes the one it operates on as a parameter!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHiUm1z1B6zE"
      },
      "source": [
        "img.thumbnail((200, 200)) # Target thumbnail size\n",
        "img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEqlz85XY5MA"
      },
      "source": [
        "To save an image, simply call save on the variable with a filename/path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi2ezQJ8u0Ew"
      },
      "source": [
        "img.save(\"small.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "gvGD2Hicy_Tt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOwpzJ1SY5MA"
      },
      "source": [
        "## 2. What is an image anyway?\n",
        "\n",
        "In Python (for deep learning), images are arrays, i.e. multi-dimensional matrices (arrays). Color images have three channels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YNabKCo6kV5"
      },
      "source": [
        "# For convenience\n",
        "def show_np(x):\n",
        "    img = PIL.Image.fromarray(x)\n",
        "    toolbox.show_img(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzDQJ4GH6XTn"
      },
      "source": [
        "a = np.ones((20,20,3), dtype=np.uint8) * 255 # Multiply with scalar\n",
        "print(a.shape) # Show the \"shape\" of a matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a)"
      ],
      "metadata": {
        "id": "eO38rc-tzNaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_np(a)"
      ],
      "metadata": {
        "id": "00eBiEoVzMHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6ZQyFmtY5MB"
      },
      "source": [
        "### Manipulating pixels with slicing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNUKn71F6afO"
      },
      "source": [
        "b = np.zeros((20,20,3), dtype=np.uint8)\n",
        "b[:,:,0] = 255\n",
        "show_np(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_np = np.array(img)"
      ],
      "metadata": {
        "id": "T4aNJhhUzTAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k04qW9UA6cjC"
      },
      "source": [
        "img_np[0:100,0:100,2] = 0 # Remove the red channel in the upper left corner\n",
        "show_np(img_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G28bTtnXY5MB"
      },
      "source": [
        "### Exercises H\n",
        "\n",
        "1. Create a grey 300x300 pixel image and display it.\n",
        "2. Re-color 1/3 of the image red, 1/3 green, 1/3 blue and display it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lhn1LgMS7mpk"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYWNSMkQHmj1"
      },
      "source": [
        "## 3. Colors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mGrWenc-dLv"
      },
      "source": [
        "Let's get the average color of all images in a dataset. First, load the WGA dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paths = toolbox.get_all_files(\"wga\", ext=\"jpg\")\n",
        "print(paths[:5])"
      ],
      "metadata": {
        "id": "HxHm3L88Aac3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(paths)"
      ],
      "metadata": {
        "id": "crWCnyuFOUrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu5pbniA-chG"
      },
      "source": [
        "def avg_color(np_img):\n",
        "    avg_color_per_row = np.average(np_img, axis=0)\n",
        "    avg_color = np.average(avg_color_per_row, axis=0)\n",
        "    return avg_color"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMxpNWBm_fSE"
      },
      "source": [
        "for path in paths[:3]: # Only try this on a subset\n",
        "    img = toolbox.load_img(path)\n",
        "    img.thumbnail((200,200)) # In-place!\n",
        "    np_img = np.array(img)\n",
        "\n",
        "    color_img = toolbox.color_img(50, avg_color(np_img))\n",
        "\n",
        "    display(img)\n",
        "    display(color_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j18h6sEgGFci"
      },
      "source": [
        "Now this seems correct but not very useful. It turns out what we actually want are the *dominant* colors, not the average color. And we can get these by applying a machine learning technique called [k-means clustering](https://en.wikipedia.org/wiki/K-means_clustering). To visualize the colors we will use a function provided by the class toolbox called `make_palette` that takes an array of colors and creates a plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4XWEZbwFmos"
      },
      "source": [
        "for path in paths[:3]: # Only try this on a subset\n",
        "    img = toolbox.load_img(path)\n",
        "    img.thumbnail((200,200)) # In-place!\n",
        "    img_np = np.array(img)\n",
        "    # Result: 200x200x3 matrix\n",
        "\n",
        "    km = KMeans(n_clusters=15) # Set up algorithm to find 5 clusters\n",
        "    km.fit(img_np.reshape(-1, 3)) # Flatten image but keep color planes: -1 means the computer will figure the dimension itself!\n",
        "    centers = km.cluster_centers_ # Get the center points of the clusters\n",
        "    palette = toolbox.make_palette(centers) # Make a palette image\n",
        "\n",
        "    toolbox.show_img(img)\n",
        "    toolbox.show_img(palette)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "j1mBf0gHH5_T"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlPukr5btiTf"
      },
      "source": [
        "## 4. Clustering images..."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ... by \"brightness\""
      ],
      "metadata": {
        "id": "Rqr3KmVeA8_y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract the features by \"flattening\" the image - we are simply concatenating all color values into one huge list."
      ],
      "metadata": {
        "id": "ncrwGhTLBDKL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfNKozUb0vDl"
      },
      "source": [
        "features = np.zeros((len(paths), 32*32*3))\n",
        "for i, path in enumerate(tqdm(paths)):\n",
        "    img = toolbox.load_img(path)\n",
        "    features[i] = toolbox.flatten_img(img, 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYnsz0BIsUd3"
      },
      "source": [
        "print(features.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CyDiBtgt0Yf"
      },
      "source": [
        "This gives us 3072-dimensional features, we have to reduce them down to Euclidean space somehow. We will use the [UMAP algorithm](https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction#Uniform_manifold_approximation_and_projection) for this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD88hC6Er8d9"
      },
      "source": [
        "reduced_features = toolbox.reduce_features(features)\n",
        "print(reduced_features.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's see how that looks"
      ],
      "metadata": {
        "id": "q0IrrwTqBQzt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1P2XtiBsdvU"
      },
      "source": [
        "plot = toolbox.plot_imgs_features(paths, 50, reduced_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY12eF7ftllC"
      },
      "source": [
        "plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPoQ8Uj6wHY0"
      },
      "source": [
        "plot.save(\"plot_raw.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Xp0fjuM3Qnj"
      },
      "source": [
        "### ... using CLIP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8_2cYJwCQvC"
      },
      "source": [
        "Usually, however, color will not tell us much about an image dataset. Instead, we can leverage state-of-the-art, fully-trained neural networks, like [CLIP](https://openai.com/blog/clip/), that know something about the *content* of images."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.zeros((len(paths), 512))\n",
        "for i, path in enumerate(tqdm(paths)):\n",
        "    img = toolbox.load_img(path)\n",
        "    features[i] = toolbox.CLIP_img(img)"
      ],
      "metadata": {
        "id": "6OUWDGYBBo-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(features.shape)"
      ],
      "metadata": {
        "id": "hc6fp9f6B0FV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61ouUSotCnP5"
      },
      "source": [
        "CLIP gives us 512-dimensional embeddings, we have to reduce them down to Euclidean space somehow. Again we will use the UMAP algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aPY5QyRAVzo"
      },
      "source": [
        "reduced_features = toolbox.reduce_features(features)\n",
        "print(reduced_features.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsTjcXL5wU_8"
      },
      "source": [
        "plot = toolbox.plot_imgs_features(paths, 200, reduced_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLWrOiFDwYIk"
      },
      "source": [
        "plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW_yCFlJyPf-"
      },
      "source": [
        "plot.save(\"plot_clip.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "wzwzW0WXH74A"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYMd-ixTwaAx"
      },
      "source": [
        "## 5. Advanced clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many interesting clusters that we can see in the plot - can we automate this process, too?"
      ],
      "metadata": {
        "id": "JodaUqmmB59h"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycLWz2EbmyBm"
      },
      "source": [
        "n_clusters = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOyZJRkeXq0S"
      },
      "source": [
        "km = KMeans(n_clusters=n_clusters)\n",
        "km.fit(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEcbTsufYEFG"
      },
      "source": [
        "km.labels_.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are trying to find 5 clusters in 2200 images - here is what the algorihtm found"
      ],
      "metadata": {
        "id": "E9XypN6kCb87"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22CLovUcimKf"
      },
      "source": [
        "km.labels_[:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try to visualize this"
      ],
      "metadata": {
        "id": "09J8Le_YCima"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EPOijKekJId"
      },
      "source": [
        "clusters = {}\n",
        "for c in range(n_clusters):\n",
        "    clusters[c] = []\n",
        "    for i, path in enumerate(paths):\n",
        "        if km.labels_[i] == c:\n",
        "            clusters[c].append(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5X1zSfolmQ2"
      },
      "source": [
        "for c in range(n_clusters):\n",
        "    toolbox.show_img(toolbox.plot_imgs_grid(clusters[c], 50))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No we will visualize where the clusters are in the overview plot"
      ],
      "metadata": {
        "id": "6pWJ5RlhICF1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKE1XomipBLi"
      },
      "source": [
        "borders = []\n",
        "p = toolbox.random_palette(n_clusters)\n",
        "for i, path in enumerate(paths):\n",
        "    borders.append(p[km.labels_[i]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT5WSl6yZZJG"
      },
      "source": [
        "plot = toolbox.plot_imgs_features(paths, 50, reduced_features, borders)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl6lawSvAyll"
      },
      "source": [
        "plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKb52Xwqybx_"
      },
      "source": [
        "plot.save(\"plot_clip_borders_clusters.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we can use the colored borders to add metadata back in!"
      ],
      "metadata": {
        "id": "loQM4OCgnGZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "borders = []\n",
        "p = toolbox.random_palette(2)\n",
        "for i, path in enumerate(paths):\n",
        "    if \"Screen\" in path:\n",
        "        borders.append(p[0])\n",
        "    else:\n",
        "        borders.append(p[1])"
      ],
      "metadata": {
        "id": "9OXVJzi_nLBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot = toolbox.plot_imgs_features(paths, 50, reduced_features, borders)"
      ],
      "metadata": {
        "id": "L2He0qADnbYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot"
      ],
      "metadata": {
        "id": "aLy9SXV4oGyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot.save(\"plot_clip_borders_classes.jpg\")"
      ],
      "metadata": {
        "id": "lvBLsM1doFmn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}